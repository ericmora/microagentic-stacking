# МАНИФЕСТ МИКРОАГЕНТНОГО СТЕКИНГА (THE MICROAGENTIC STACKING MANIFESTO)

> Примечание: Этот перевод был автоматически сгенерирован Gemini 3.

## От алхимии промптов к масштабируемой разработке программного обеспечения


## 1. Преамбула: Конец монолита

Мы наблюдаем крах «Промпт-инжиниринга» как изолированной дисциплины. Попытка решить сложные бизнес-процессы с помощью одной гигантской инструкции для фундаментальной модели (LLM) оказалась хрупкой, непредсказуемой стратегией, которую невозможно подвергнуть аудиту в масштабах предприятия.

Академические исследования подтвердили еще в 2023 году, что рассмотрение LLM как монолитных «черных ящиков» для сложных задач было тупиковым путем [7]. Сегодня ведущие институты, такие как Калифорнийский университет в Беркли (UC Berkeley), подтверждают, что уровень развития техники больше не достигается с помощью более крупных отдельных моделей, а с помощью «Составных систем ИИ» (Compound AI Systems), которые оркестрируют множество компонентов [13], — тренд, подтвержденный новыми архитектурными паттернами, наблюдаемыми в индустрии ведущими фирмами, такими как a16z [15].

ИИ — это не магия; это вероятностные вычисления. Как таковой, он должен подчиняться тем же инженерным дисциплинам, которые позволяли программному обеспечению масштабироваться десятилетиями: разделение (decoupling), модульность и строгие контракты. Будущее ИИ не в больших промптах, а в лучшей системной архитектуре [10].

Мы предлагаем радикальный сдвиг парадигмы: прекратить создание монолитных чат-ботов и начать оркестровку составных архитектур.

Мы называем этот стандарт **Микроагентный стекинг (Microagentic Stacking — MAS)**.


## 2. Основная философия

Наша методология не стремится создать общий искусственный интеллект (AGI). Она стремится создавать надежные корпоративные системы посредством оркестровки специализированных когнитивных единиц.

Мы основываемся на трех незыблемых столпах:

1. **Процесс важнее ИИ:** ИИ не определяет рабочий процесс; бизнес-процесс определяет, где и как используется ИИ.
2. **Атомарность важнее универсальности:** Когнитивная сложность решается путем разбиения ее на мельчайшие и неделимые компоненты.
3. **Инкрементальный рост:** Системы не проектируются «законченными»; они развиваются слой за слоем, процесс за процессом, от простого MVP к сложной экосистеме.


## 3. Технические принципы MAS

Для реализации системы MAS необходимо соблюдать следующие архитектурные законы, унаследованные от десятилетий надежных принципов разработки программного обеспечения:

### I. Закон атомарного микроагента (Единственная ответственность)

Микроагент должен выполнять одну когнитивную задачу и выполнять ее идеально. Это прямое применение принципа единственной ответственности (SRP) к компонентам ИИ [2]. Если агент пытается «искать информацию, анализировать ее и писать ответ», он плохо спроектирован. Его необходимо разделить на трех разных агентов.

### II. Изоляция «черного ящика» (Принцип черного ящика)

Внутренняя работа микроагента абсолютно приватна и недоступна для остальной системы, следуя принципам проектирования микросервисов и ограниченным контекстам [1].

* Оркестратор не знает, какой промпт используется внутри.
* Оркестратор не знает, какая модель (GPT-4, Claude, локальная Llama 3) выполняет задачу.

Эта абстракция позволяет проводить рефакторинг, оптимизацию затрат и смену моделей внутри агента, не нарушая вышестоящий процесс.

### III. Радикальное разделение и контракты (Разделение через схему)

Микроагенты являются агностиками по отношению друг к другу. Они управляются методологией «Проектирование по контракту» (Design by Contract), где предусловия и постусловия строгие [3].

* **Жесткие контракты:** Каждый агент строго определяет, какие данные он принимает (Input Schema) и какие данные возвращает (Output Schema), используя стандартные форматы (например, JSON Schema, Pydantic).
* **Оркестратор как трансформатор:** Исключительной ответственностью бизнес-процесса (оркестратора) является принятие выходных данных от Агента А, трансформация или маппинг данных при необходимости и внедрение их в Агента B с соблюдением его контракта.

### IV. Иерархическая и компонуемая оркестровка

Агенты — это детали, но ценность заключается в сборке. Сложный интеллект возникает не из одной модели, а из координации множества частей [4].

* **Процессы, вызывающие агентов:** Рабочий процесс оркестрирует последовательность микроагентов.
* **Процессы, вызывающие процессы:** Процесс высокого уровня может вызывать другой процесс, как если бы это был просто еще один агент, обеспечивая бесконечную рекурсивную композицию.


## 4. Соглашение об корпоративном управлении

Автономия ИИ внутри компании требует строгого контроля. MAS — это не просто код; это фреймворк ответственности и надежности. Эксперты по ML-инжинирингу неоднократно указывали, что разрыв между демо-версией и системой в продакшене заключается в отсутствии инженерной строгости, оценки и контроля рисков [14]. Данные показывают, что надежность резко снижается по мере роста неконтролируемой автономии [8].

### 1. Атомарная подотчетность (Atomic Accountability)

«Системной ошибки» не существует. Каждые сгенерированные выходные данные должны содержать неизменяемую подпись трассировки (immutable trace signature), идентифицирующую, какой конкретный микроагент, какая версия промпта и какая именно модель сгенерировала их, для мгновенного судебно-медицинского аудита.

### 2. Неизменность и версионирование (Prompt SemVer)

Промпт — это код. Он должен находиться под контролем версий. Любое изменение внутренней инструкции, каким бы незначительным оно ни было, представляет собой новую неизменяемую версию агента (v1.0 -> v1.1). В продакшене нет «горячих» изменений.

### 3. Строгая валидация ввода (Fail Fast)

Мы действуем как строгий таможенный контроль. Прежде чем агент начнет работать, система автоматически проверяет, что данные, которые он собирается получить, полностью соответствуют его входному контракту. Если данные не подходят на 100%, процесс немедленно останавливается с видимой ошибкой. Этот паттерн «Fail Fast» (быстрый отказ) необходим для стабильности распределенных систем [5].

### 4. Минимальные контекстные привилегии

Информация регулируется принципом «need to know» (необходимость знать). Ни один агент не получает глобальный контекст операции, только данные, строго необходимые для его микрозадачи. Это критически важно, так как было показано, что производительность LLM значительно ухудшается при перегрузке нерелевантным контекстом (феномен «Lost in the Middle») [6].

### 5. Экономика единицы (FinOps на атомарном уровне)

Стоимость должна быть наблюдаема для каждой единицы. Система должна быть способна сообщать точную стоимость выполнения каждого отдельного микроагента.


## 5. Фреймворк качества (Testing Framework)

Поскольку LLM вероятностны, тестирование в MAS должно быть статистическим и многоуровневым.

* **Уровень 1: Модульные оценки (Unit Evals).** Каждый микроагент должен пройти «Золотой набор данных» (Golden Dataset) с определенным порогом статистического успеха (>95%) перед развертыванием.
* **Уровень 2: Контрактное тестирование (Интеграция).** Мы проверяем, что части подходят друг другу, используя моки (Mocking). Мы гарантируем, что оркестратор правильно трансформирует данные между агентами без необходимости запуска моделей.
* **Уровень 3: Процессное тестирование (E2E).** Мы проверяем, что полный бизнес-поток соответствует функциональным требованиям и требованиям задержки.


## 6. Три измерения масштабируемости

В монолитной парадигме масштабирование дорого и хрупко. В MAS масштабируемость является естественным следствием архитектуры.

### I. Техническая масштабируемость: «Stateless by Design»

Наши микроагенты — это единицы выполнения без состояния (stateless). Это позволяет развертывать от простых архитектур до асинхронных систем на основе очередей (Event-Driven) для управления массовыми пиками нагрузки без необходимости изменения внутренней логики агентов.

### II. Когнитивная масштабируемость: «Разделяй и властвуй»

Мы избегаем когнитивного ухудшения длинных контекстов [6]. Чтобы решать более сложные задачи, мы не расширяем контекст; мы добавляем в цепочку больше специализированных агентов. Мы поддерживаем постоянную надежность независимо от сложности задачи.

### III. Организационная масштабируемость: Модульная разработка

Мы устраняем узкое место разработки. Благодаря строгим контрактам и «черным ящикам» несколько команд могут работать, оптимизировать и развертывать разные микроагенты параллельно без конфликтов кода и без остановки экосистемы.


## 7. Эталонная архитектура: Движок RFP

Чтобы продемонстрировать надежность Микроагентного стекинга в критической среде, мы анализируем логическую архитектуру системы автоматического ответа на запросы предложений (RFP). Этот процесс требует строгого разделения между рассуждениями (ИИ) и бизнес-данными (SQL). Индустрия движется к моделям, где оркестровка управляется явными конечными автоматами, а не автономными циклами [9].

### Микроагентный стек

* **Оркестратор (State Machine):** Ядро системы. Это не ИИ. Это движок рабочего процесса, который управляет статусом тендера и направляет трафик между агентами и базами данных.
* **Микроагент A (Экстрактор):** Получает необработанный текст из PDF. Его единственная миссия — вернуть структурированный JSON с техническими требованиями. Он не высказывает мнений, только извлекает.
* **Интеграционный слой (Legacy):** Оркестратор берет ID, извлеченные Агентом A, и запрашивает ERP для получения цен и запасов. Ключевой принцип: ИИ никогда не придумывает цены.
* **Микроагент B (Аудитор рисков):** Получает юридические положения. Если он обнаруживает неприемлемые риски, он активирует «Автоматический выключатель» (Circuit Breaker) [5], и оркестратор останавливает процесс до составления черновика.
* **Микроагент C (Финальный составитель):** Активируется только в том случае, если предыдущие шаги действительны. Генерирует предложение, используя исключительно «чистые данные», которые предоставляет оркестратор.


## 8. Заключение: Эволюция как стандарт

Микроагентный стекинг — это не статичное решение; это методология для непрерывного роста. Она позволяет начать с простого MVP и развиваться в сложные экосистемы, добавляя возможности и оптимизируя отдельные компоненты без риска регрессии. Сообщество разработчиков в целом принимает этот переход от монолитов к агентным рабочим процессам как новую парадигму миграции рабочих нагрузок [12].

Мы отвергаем хаос. Мы принимаем структуру.
**Мы не строим демо-версии. Мы строим архитектуру.**

**Ведущий автор и сопровождающий:** Эрик Мора Хуан (Eric Mora Juan) (<ericmora82@gmail.com>)
**Опубликовано:** Январь 2026
Это живой стандарт. Вклад сообщества приветствуется.


## Ссылки

### Основы программной инженерии

1. Newman, S. (2021). Building Microservices: Designing Fine-Grained Systems (2nd Ed.). O'Reilly Media.
2. Martin, R. C. (2017). Clean Architecture: A Craftsman's Guide to Software Structure and Design. Prentice Hall.
3. Meyer, B. (1992). "Applying 'Design by Contract'". Computer, 25(10), 40-51. IEEE. Link: [https://ieeexplore.ieee.org/document/161279](https://ieeexplore.ieee.org/document/161279)
4. Hohpe, G., & Woolf, B. (2003). Enterprise Integration Patterns: Designing, Building, and Deploying Messaging Solutions. Addison-Wesley.
5. Nygard, M. T. (2018). Release It!: Design and Deploy Production-Ready Software (2nd Ed.). Pragmatic Bookshelf.

### Исследования и архитектура систем ИИ (Уровень техники)

1. Liu, N. F., et al. (2023). "Lost in the Middle: How Language Models Use Long Contexts". arXiv preprint arXiv:2307.03172. Link: [https://arxiv.org/abs/2307.03172](https://arxiv.org/abs/2307.03172)
2. Khattab, O., et al. (Stanford NLP) (2023). "DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines". arXiv preprint arXiv:2310.03714. Link: [https://arxiv.org/abs/2310.03714](https://arxiv.org/abs/2310.03714)
3. Wang, L., et al. (2024). "On the Robustness of Large Language Models for Agentic Tasks". arXiv preprint arXiv:2402.05818. Link: [https://arxiv.org/abs/2402.05818](https://arxiv.org/abs/2402.05818)
4. LangChain Team (2024). "LangGraph: Building Language Agents as Graphs". LangChain Blog. Link: [https://blog.langchain.dev/langgraph/](https://blog.langchain.dev/langgraph/)
5. Husain, H. (2023). "AI Engineering is the New Software Engineering". Hamel's Blog. Link: [https://hamel.dev/blog/posts/ai-eng-is-new-sw-eng/](https://hamel.dev/blog/posts/ai-eng-is-new-sw-eng/)
6. Shopify Engineering (2024). "How Shopify Uses LLMs for Commerce". Shopify Engineering Blog.
7. Daga, D. (Medium). "From Monoliths to Agentic Workflows: The New Paradigm of Workload Migration". Link: [https://medium.com/@dagadeepansh/from-monoliths-to-agentic-workflows-the-new-paradigm-of-workload-migration-6f503f3837cc](https://medium.com/@dagadeepansh/from-monoliths-to-agentic-workflows-the-new-paradigm-of-workload-migration-6f503f3837cc)
8. Berkeley Artificial Intelligence Research (BAIR) (2024). "The Shift from Models to Compound AI Systems". BAIR Blog. Link: [https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/)
9. Huyen, C. (2023). "Building LLM applications for production". Chip Huyen's Blog. Link: [https://huyenchip.com/2023/04/11/llm-engineering.html](https://huyenchip.com/2023/04/11/llm-engineering.html)
10. Andreessen Horowitz (a16z) (2023/2024). "Emerging Architectures for LLM Applications". a16z Technology Blog. Link: [https://a16z.com/emerging-architectures-for-llm-applications/](https://a16z.com/emerging-architectures-for-llm-applications/)

### Недавний отраслевой консенсус (2025)

1. Forrester Research (2025). "The Agentic AI Reality Check: Why Governance and Orchestration Will Define the Next Era of Enterprise Automation." (Tech Trends Report).
